name: Scheduled Scraper

on:
  schedule:
    - cron: "0 2 * * *"

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Build scraper image
        run: docker build -t scraper -f scraper/Dockerfile .

      - name: Run scraper
        env:
          DB_URL: ${{ secrets.DB_URL }}
          HEADLESS: true
        run: |
          docker run --rm \
            -e DB_URL \
            -e HEADLESS \
            scraper \
            python -m scraper.cli.scrape_all

      - name: Upload SQLite database to MyDevil
        env:
          MYDEVIL_USER: ${{ secrets.MYDEVIL_USER }}
          MYDEVIL_HOST: ${{ secrets.MYDEVIL_HOST }}
          MYDEVIL_PATH: ${{ secrets.MYDEVIL_PATH }}
          MYDEVIL_SSH_KEY: ${{ secrets.MYDEVIL_SSH_KEY }}
        run: |
          mkdir -p ~/.ssh
          echo "$MYDEVIL_SSH_KEY" > ~/.ssh/mydevil_key
          chmod 600 ~/.ssh/mydevil_key
          rsync -av -e "ssh -i ~/.ssh/mydevil_key -o StrictHostKeyChecking=no" \
            data/pharmacy_prices.sqlite \
            "$MYDEVIL_USER@$MYDEVIL_HOST:$MYDEVIL_PATH"
